Integrations
============

This page lists the main integrations available in InferencePort AI.

Core Integrations
-----------------

* **Ollama**: local model runtime used for local chat and model management.
* **Hugging Face**: model discovery/import and Spaces demos.
* **Websites**: save and launch external AI websites from the app.

Data and Account Integrations
-----------------------------

* **Optional sign-in**: email, GitHub, or Google authentication.
* **Optional sync**: remote session sync when enabled in Settings.

Advanced Networking Integrations
--------------------------------

* **Remote host support**: connect to model hosts on other machines.
* **Hosting/proxy mode**: run a local proxy server with allowlisted emails.

Platform Integrations
---------------------

* **Cross-platform desktop support**: Windows, macOS, and Linux.
* **Microsoft Store distribution**: Windows install/update option.

See Also
--------

* :doc:`getting-started`
* :doc:`user-guide`
* :doc:`troubleshooting`
